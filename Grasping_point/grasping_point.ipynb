{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for one piece of the experiment, we have four pointclouds and a .cvs contains position, rotation and grasp_position\n",
    "step1. let 3 camera rgb and depth images same number\n",
    "step2. let image and action same number\n",
    "step3. first appear 1 (from 0), select the image and action which 5 images before the timestep.\n",
    "step4. add grasp position to .csv\n",
    "step5. select the corresponding images\n",
    "step6. try sam2 to do the segmentation get the mask and apply the mask\n",
    "step6. create the pointcloud (4 pointcloud in total)\n",
    "(step7. crop the pointcloud)\n",
    "so the dataset i sent to leo: for one experiment, .csv + 4 pointcloud*2\n",
    "model: pointnet++ & pointbert -- try on segmented pointcloud and croped pointcloud (single view and merged view)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "\n",
    "# Path to the base directory where the subfolders are located\n",
    "base_path = \"/media/ubb/4T/human_demonstration/arif_checked_process1\"\n",
    "\n",
    "# Collect all paths for 'tracker_right_zed_modified.csv' and 'tracker_left_zed_modified.csv'\n",
    "csv_files = glob.glob(os.path.join(base_path, \"**/*zed_modified.csv\"), recursive=True)\n",
    "\n",
    "# Prepare a DataFrame to store all changes\n",
    "all_changes = pd.DataFrame(columns=['name', 'subname', 'time', 'pc_time', 'position', 'orientation', 'l_or_r','grasp_position'])\n",
    "\n",
    "# Convert position dictionary to numpy array\n",
    "def position_to_nparray(position):\n",
    "    return np.array([position['x'], position['y'], position['z']])\n",
    "\n",
    "# Convert quaternion dictionary to numpy array\n",
    "def quaternion_to_nparray(quaternion):\n",
    "    return np.array([quaternion['w'], quaternion['x'], quaternion['y'], quaternion['z']])\n",
    "\n",
    "# Function to calculate the extended point\n",
    "def calculate_extended_point(position, quaternion, extension_vector):\n",
    "    position_np = position_to_nparray(position)\n",
    "    quaternion_np = quaternion_to_nparray(quaternion)\n",
    "    R = o3d.geometry.get_rotation_matrix_from_quaternion(quaternion_np)\n",
    "    # extension_vector = np.array([extension_length_x, extension_length_y, extension_length_z])\n",
    "    extended_vector = np.dot(R, extension_vector)\n",
    "    extended_point = position_np + extended_vector\n",
    "    return extended_point.tolist()\n",
    "\n",
    "# Function to find every occurrence of a change from 0 to 1 in the 'gripper' column and collect the data\n",
    "def find_gripper_changes(csv_path):\n",
    "    # Extract the folder and subfolder name\n",
    "    parts = csv_path.split(os.sep)\n",
    "    print(parts)\n",
    "    name = parts[-5]  # Adjust if necessary\n",
    "    subname = parts[-4]  # Adjust if necessary\n",
    "    side = 'right' if 'right' in os.path.basename(csv_path) else 'left'\n",
    "    \n",
    "    try:\n",
    "        # Read the CSV file\n",
    "        data = pd.read_csv(csv_path)\n",
    "        data['position'] = data['position'].apply(eval)\n",
    "        data['orientation'] = data['orientation'].apply(eval)\n",
    "        \n",
    "        # Track the last gripper state to identify changes from 0 to 1\n",
    "        last_gripper = 0\n",
    "        for index, row in data.iterrows():\n",
    "            if row['gripper'] == 1 and last_gripper == 0:\n",
    "                row = data.iloc[index]\n",
    "                if index >=5:\n",
    "                    prev_row = data.iloc[index - 5]\n",
    "                extension_vector = np.array([0.02, 0.045, 0.10]) if side == 'right' else np.array([-0.02, 0.045, 0.10])\n",
    "                grasp_position = calculate_extended_point(\n",
    "                        row['position'],\n",
    "                        row['orientation'],\n",
    "                        extension_vector\n",
    "                    )\n",
    "                all_changes.loc[len(all_changes)] = [name, subname, row['time'], prev_row['time'], row['position'], row['orientation'], side, grasp_position]\n",
    "            last_gripper = row['gripper']\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process {csv_path}: {str(e)}\")\n",
    "\n",
    "# Process each CSV file found\n",
    "for csv_file in csv_files:\n",
    "    find_gripper_changes(csv_file)\n",
    "\n",
    "# Save the collected data to a new CSV file\n",
    "all_changes.to_csv(\"/media/ubb/4T/human_demonstration/arif_checked_process1/gripper_changes.csv\", index=False)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'media', 'ubb', '4T', 'human_demonstration', 'useful_data', 'xie_checked_process', 'ssshirt_blue', 'bag', 'tracker_total_zed_modified.csv']\n",
      "['', 'media', 'ubb', '4T', 'human_demonstration', 'useful_data', 'xie_checked_process', 'lstshirt_white', 'bag', 'tracker_total_zed_modified.csv']\n",
      "['', 'media', 'ubb', '4T', 'human_demonstration', 'useful_data', 'xie_checked_process', 'napkin_brown45', 'bag', 'tracker_total_zed_modified.csv']\n",
      "['', 'media', 'ubb', '4T', 'human_demonstration', 'useful_data', 'xie_checked_process', 'napkin_fleek45', 'bag', 'tracker_total_zed_modified.csv']\n",
      "['', 'media', 'ubb', '4T', 'human_demonstration', 'useful_data', 'xie_checked_process', 'napkin_grey45', 'bag', 'tracker_total_zed_modified.csv']\n",
      "['', 'media', 'ubb', '4T', 'human_demonstration', 'useful_data', 'xie_checked_process', 'lstshirt_black', 'bag', 'tracker_total_zed_modified.csv']\n",
      "['', 'media', 'ubb', '4T', 'human_demonstration', 'useful_data', 'xie_checked_process', 'napkin_pink45', 'bag', 'tracker_total_zed_modified.csv']\n",
      "['', 'media', 'ubb', '4T', 'human_demonstration', 'useful_data', 'xie_checked_process', 'napkin_red45', 'bag', 'tracker_total_zed_modified.csv']\n",
      "['', 'media', 'ubb', '4T', 'human_demonstration', 'useful_data', 'xie_checked_process', 'ssshirt_pink', 'bag', 'tracker_total_zed_modified.csv']\n",
      "['', 'media', 'ubb', '4T', 'human_demonstration', 'useful_data', 'xie_checked_process', 'ssshirt_yellow', 'bag', 'tracker_total_zed_modified.csv']\n",
      "['', 'media', 'ubb', '4T', 'human_demonstration', 'useful_data', 'xie_checked_process', 'towel_blue', 'bag', 'tracker_total_zed_modified.csv']\n",
      "['', 'media', 'ubb', '4T', 'human_demonstration', 'useful_data', 'xie_checked_process', 'towel_pink', 'bag', 'tracker_total_zed_modified.csv']\n",
      "['', 'media', 'ubb', '4T', 'human_demonstration', 'useful_data', 'xie_checked_process', 'lstshirt_brown', 'bag', 'tracker_total_zed_modified.csv']\n",
      "['', 'media', 'ubb', '4T', 'human_demonstration', 'useful_data', 'xie_checked_process', 'towel_red', 'bag', 'tracker_total_zed_modified.csv']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import glob\n",
    "\n",
    "# Path to the base directory where the subfolders are located\n",
    "base_path = \"/media/ubb/4T/human_demonstration/useful_data/xie_checked_process\"\n",
    "\n",
    "# Path for the merged tracker file\n",
    "# csv_file = os.path.join(base_path, \"bag\",\"tracker_total_zed_modified.csv\")\n",
    "csv_files = glob.glob(os.path.join(base_path, \"**/*tracker_total_zed_modified.csv\"), recursive=True)\n",
    "# Prepare a DataFrame to store all changes\n",
    "all_changes = pd.DataFrame(columns=[\n",
    "    'name', 'subname','index', 'time', 'pc_time',\n",
    "    'original_pos_left', 'original_ori_left',\n",
    "    'original_pos_right', 'original_ori_right',\n",
    "    'grasp_pos_left', 'grasp_pos_right', \n",
    "    'left_gripper', 'right_gripper'\n",
    "])\n",
    "\n",
    "# def calculate_average_position(data, start_index, end_index, pos_column):\n",
    "#     positions = []\n",
    "#     for i in range(start_index, end_index + 1):\n",
    "#         pos = data.loc[i, pos_column]\n",
    "#         if isinstance(pos, str):\n",
    "#             pos = eval(pos)\n",
    "#         positions.append(np.array([pos['x'], pos['y'], pos['z']]))\n",
    "#     return np.mean(np.array(positions), axis=0) if positions else np.array([0, 0, 0])\n",
    "\n",
    "def position_to_nparray(position):\n",
    "    return np.array([position['x'], position['y'], position['z']])\n",
    "\n",
    "# Convert quaternion dictionary to numpy array\n",
    "def quaternion_to_nparray(quaternion):\n",
    "    return np.array([quaternion['w'], quaternion['x'], quaternion['y'], quaternion['z']])\n",
    "\n",
    "# Function to calculate the extended point\n",
    "def calculate_extended_point(position, quaternion, extension_vector):\n",
    "    position_np = position_to_nparray(position)\n",
    "    quaternion_np = quaternion_to_nparray(quaternion)\n",
    "    R = o3d.geometry.get_rotation_matrix_from_quaternion(quaternion_np)\n",
    "    extended_vector = np.dot(R, extension_vector)\n",
    "    extended_point = position_np + extended_vector\n",
    "    return extended_point.tolist()\n",
    "\n",
    "# Function to process tracker data\n",
    "def process_tracker_data(csv_path):\n",
    "    global all_changes\n",
    "    parts = csv_path.split(os.sep)\n",
    "    print(parts)\n",
    "    name = parts[-4]  # Adjust if necessary\n",
    "    subname = parts[-3] \n",
    "    changes = pd.DataFrame(columns=all_changes.columns)\n",
    "    try:\n",
    "        # Read the CSV file\n",
    "        data = pd.read_csv(csv_path)\n",
    "        data['left_pos'] = data['left_pos'].apply(eval).apply(np.array)\n",
    "        data['left_ori'] = data['left_ori'].apply(eval).apply(np.array)\n",
    "        data['right_pos'] = data['right_pos'].apply(eval).apply(np.array)\n",
    "        data['right_ori'] = data['right_ori'].apply(eval).apply(np.array)\n",
    "\n",
    "        # Track the last gripper state to identify changes from 0 to 1\n",
    "        last_gripper_left = 0\n",
    "        last_gripper_right = 0\n",
    "\n",
    "        for index, row in data.iterrows():\n",
    "            changed_left = row['left_gripper'] == 1 and last_gripper_left == 0\n",
    "            changed_right = row['right_gripper'] == 1 and last_gripper_right == 0\n",
    "\n",
    "            pc_time = data.iloc[index - 8]['time'] if index >= 8 else row['time']\n",
    "            if changed_left or changed_right:\n",
    "            # Calculate extended positions\n",
    "                # pc_time_index = max(0, index - 13)\n",
    "                # average_pos_left = calculate_average_position(data, pc_time_index, index, 'left_pos')\n",
    "                # average_pos_right = calculate_average_position(data, pc_time_index, index, 'right_pos')\n",
    "                \n",
    "                extension_vector_left = np.array([0.03, 0.03, 0.095])\n",
    "                extension_vector_right = np.array([-0.03, 0.03, 0.095])\n",
    "                grasp_pos_left = calculate_extended_point(row['left_pos'], row['left_ori'], extension_vector_left) if changed_left else None\n",
    "                grasp_pos_right = calculate_extended_point(row['right_pos'], row['right_ori'], extension_vector_right) if changed_right else None\n",
    "            \n",
    "            # Append to all_changes DataFrame\n",
    "                # all_changes.loc[len(all_changes)] = [\n",
    "                #     name, subname, index, row['time'], pc_time, row['left_pos'], row['left_ori'],\n",
    "                #     row['right_pos'], row['right_ori'], \n",
    "                #     grasp_pos_left, grasp_pos_right, \n",
    "                #     int(changed_left), int(changed_right)\n",
    "                # ]\n",
    "                changes.loc[len(changes)] = [\n",
    "                    name, subname, index, row['time'], pc_time, row['left_pos'], row['left_ori'],\n",
    "                    row['right_pos'], row['right_ori'], \n",
    "                    grasp_pos_left, grasp_pos_right, \n",
    "                    int(changed_left), int(changed_right)\n",
    "                ]\n",
    "\n",
    "\n",
    "            last_gripper_left = row['left_gripper']\n",
    "            last_gripper_right = row['right_gripper']\n",
    "        \n",
    "        if not changes.empty:\n",
    "            changes = changes.iloc[1:].reset_index(drop=True)\n",
    "            all_changes = pd.concat([all_changes, changes])\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process {csv_path}: {str(e)}\")\n",
    "\n",
    "for csv_file in csv_files:\n",
    "    process_tracker_data(csv_file)\n",
    "\n",
    "\n",
    "# Save the collected data to a new CSV file\n",
    "output_csv_path = os.path.join(base_path, \"gripper_changes_new.csv\")\n",
    "all_changes.to_csv(output_csv_path, index=False)\n",
    "# print(f\"Data saved to {output_csv_path}\")\n",
    "\n",
    "#  index from 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered data saved to /media/ubb/4T/human_demonstration/useful_data/xie_checked_process/gripper_changes_filtered.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "def filter_close_indices(csv_path):\n",
    "    # Load the CSV file\n",
    "    data = pd.read_csv(csv_path)\n",
    "\n",
    "    # Create an empty list to store indices of rows to keep\n",
    "    indices_to_drop = []\n",
    "\n",
    "    # Get the 'index' column as a list\n",
    "    indices = data['index'].tolist()\n",
    "    \n",
    "    # Iterate over the indices list and check differences\n",
    "    for i in range(1, len(indices)):\n",
    "        if abs(indices[i] - indices[i - 1]) <= 20:\n",
    "            # Add both indices to the drop list if they are too close\n",
    "            indices_to_drop.append(i - 1)\n",
    "            indices_to_drop.append(i)\n",
    "\n",
    "    # Remove duplicates from indices_to_drop\n",
    "    indices_to_drop = list(set(indices_to_drop))\n",
    "\n",
    "    # Drop the rows that are too close to each other\n",
    "    filtered_data = data.drop(indices_to_drop).reset_index(drop=True)\n",
    "\n",
    "    # Save the filtered data back to CSV or to a new file\n",
    "    filtered_data.to_csv(csv_path.replace('.csv', '_filtered.csv'), index=False)\n",
    "    print(f\"Filtered data saved to {csv_path.replace('.csv', '_filtered.csv')}\")\n",
    "\n",
    "# Example usage\n",
    "csv_file_path = \"/media/ubb/4T/human_demonstration/useful_data/xie_checked_process/gripper_changes.csv\"\n",
    "filter_close_indices(csv_file_path)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "according to the .csv select image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image copying completed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "\n",
    "# Base directory for the operations\n",
    "base_path = \"/media/ubb/4T/human_demonstration/useful_data/xie_checked_process\"\n",
    "output_base = os.path.join(base_path, \"grasp_point\")\n",
    "\n",
    "# Read the filtered CSV file\n",
    "csv_path = os.path.join(base_path, \"gripper_changes_filtered.csv\")\n",
    "data = pd.read_csv(csv_path)\n",
    "\n",
    "def ensure_dir(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "def copy_images(subfolder, pc_time):\n",
    "    # Directories for images\n",
    "    subfolders = ['bag_images', 'bag_side_images', 'bag_top_images']\n",
    "    types = ['rgb', 'depth']\n",
    "\n",
    "    for s_folder in subfolders:\n",
    "        for img_type in types:\n",
    "            # Source directory\n",
    "            source_dir = os.path.join(base_path, subfolder, s_folder, img_type)\n",
    "            # Destination directory\n",
    "            dest_dir = os.path.join(output_base, subfolder, s_folder, img_type)\n",
    "            ensure_dir(dest_dir)\n",
    "            \n",
    "            # Filename construction\n",
    "            filename = f\"{pc_time}.png\"\n",
    "            source_file = os.path.join(source_dir, filename)\n",
    "            \n",
    "            # Check if the file exists before attempting to copy\n",
    "            if os.path.exists(source_file):\n",
    "                shutil.copy(source_file, dest_dir)\n",
    "                # print(f\"Copied: {source_file} to {dest_dir}\")\n",
    "            else:\n",
    "                print(f\"File not found: {source_file}\")\n",
    "\n",
    "# Iterate over the dataframe\n",
    "for index, row in data.iterrows():\n",
    "    subfolder = row['subname']  # Ensure this column name matches your CSV structure\n",
    "    pc_time = row['pc_time']\n",
    "    copy_images(subfolder, pc_time)\n",
    "\n",
    "print(\"Image copying completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now sam2 from colab i can get the mask\n",
    "prerequest: i have a rgb_for_mask folder, depth_for mask folder,mask folder -- then i apply the mask to the origal image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing all subfolders.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Define the base directory containing all the subfolders\n",
    "base_dir = \"/home/ubb/Documents/Baxter_isaac/ROS2/src/experiment_recorder/data/baxter/david_datacollect/baxter/drag_red45/pc\"\n",
    "\n",
    "# Iterate over each subfolder in the base directory\n",
    "for subfolder in os.listdir(base_dir):\n",
    "    subfolder_path = os.path.join(base_dir, subfolder)\n",
    "    \n",
    "    if os.path.isdir(subfolder_path):\n",
    "        # Define subdirectories\n",
    "        mask_dir = os.path.join(subfolder_path, \"masks\")\n",
    "        rgb_dir = os.path.join(subfolder_path, \"rgb\")\n",
    "        depth_dir = os.path.join(subfolder_path, \"depth\")\n",
    "        rgb_mask_dir = os.path.join(subfolder_path, \"rgb_mask\")\n",
    "        depth_mask_dir = os.path.join(subfolder_path, \"depth_mask\")\n",
    "\n",
    "        # Create directories for masked images if they do not exist\n",
    "        os.makedirs(rgb_mask_dir, exist_ok=True)\n",
    "        os.makedirs(depth_mask_dir, exist_ok=True)\n",
    "\n",
    "        # Get list of mask files\n",
    "        mask_files = [f for f in os.listdir(mask_dir) if f.endswith('.png')]\n",
    "\n",
    "        for mask_file in mask_files:\n",
    "            mask_path = os.path.join(mask_dir, mask_file)\n",
    "            rgb_path = os.path.join(rgb_dir, mask_file.replace('_mask.png', '.jpg'))\n",
    "            depth_path = os.path.join(depth_dir, mask_file.replace('_mask.png', '.jpg'))\n",
    "\n",
    "            # Load images\n",
    "            mask = Image.open(mask_path).convert('L')  # Ensure mask is in grayscale\n",
    "            rgb_image = Image.open(rgb_path)\n",
    "            depth_image = Image.open(depth_path)\n",
    "\n",
    "            # Convert images to arrays for masking\n",
    "            mask_array = np.array(mask) / 255\n",
    "            rgb_array = np.array(rgb_image)\n",
    "            depth_array = np.array(depth_image)\n",
    "\n",
    "            # Apply mask\n",
    "            masked_rgb = np.dstack([(rgb_array[:, :, i] * mask_array).astype(np.uint8) for i in range(3)])\n",
    "            masked_depth = (depth_array * mask_array).astype(depth_array.dtype)\n",
    "\n",
    "            # Convert arrays back to images\n",
    "            masked_rgb_image = Image.fromarray(masked_rgb)\n",
    "            masked_depth_image = Image.fromarray(masked_depth)\n",
    "\n",
    "            # Save the masked images\n",
    "            masked_rgb_image.save(os.path.join(rgb_mask_dir, f'masked_{mask_file.replace(\"_mask.png\", \".png\")}'))\n",
    "            masked_depth_image.save(os.path.join(depth_mask_dir, f'masked_{mask_file.replace(\"_mask.png\", \".png\")}'))\n",
    "\n",
    "print(\"Finished processing all subfolders.\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create pointcloud see preate_graspvisulize.ipynb --genearate pointcloud resize\n",
    "generate pointcloud for grasping point dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All missing files across subfolders: []\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "\n",
    "# Base directory containing all the subfolders\n",
    "base_dir = \"/media/ubb/4T/human_demonstration/grasp_point_top_all_sample\"\n",
    "\n",
    "# Camera intrinsics (example values, replace with actual intrinsics)\n",
    "# intrinsics =(1070.1000, 1070.4301, 939.8100, 549.6520)\n",
    "intrinsics = (1060.4000, 1060.0100, 946.0600, 496.6630)\n",
    "\n",
    "def process_images_and_generate_pointclouds(rgb_dir, depth_dir, point_dir, intrinsics):\n",
    "    if not os.path.exists(point_dir):\n",
    "        os.makedirs(point_dir)\n",
    "\n",
    "    rgb_files = sorted([f for f in os.listdir(rgb_dir) if f.endswith('.png')])\n",
    "    depth_files = sorted([f for f in os.listdir(depth_dir) if f.endswith('.png')])\n",
    "    processed_files = []\n",
    "    for rgb_file, depth_file in zip(rgb_files, depth_files):\n",
    "        rgb_image_path = os.path.join(rgb_dir, rgb_file)\n",
    "        depth_image_path = os.path.join(depth_dir, depth_file)\n",
    "\n",
    "        # Load and resize images\n",
    "        color_raw = cv2.imread(rgb_image_path)\n",
    "        color_raw = cv2.cvtColor(color_raw, cv2.COLOR_BGR2RGB)\n",
    "        depth_raw = cv2.imread(depth_image_path, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "        # Resize images to desired resolution (example: 1920x1080)\n",
    "        color_hd = cv2.resize(color_raw, (1920, 1080), interpolation=cv2.INTER_CUBIC)\n",
    "        depth_hd = cv2.resize(depth_raw, (1920, 1080), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        # Convert images for point cloud generation\n",
    "        depth_hd = o3d.geometry.Image(np.asarray(depth_hd))\n",
    "        color_hd = o3d.geometry.Image(np.asarray(color_hd))\n",
    "\n",
    "        # Generate RGBD image and point cloud\n",
    "        \n",
    "\n",
    "        rgbd_image = o3d.geometry.RGBDImage.create_from_color_and_depth(color_hd, depth_hd, convert_rgb_to_intensity=False)\n",
    "        fx, fy, cx, cy = intrinsics\n",
    "        pcd = o3d.geometry.PointCloud.create_from_rgbd_image(\n",
    "            rgbd_image,\n",
    "            o3d.camera.PinholeCameraIntrinsic(width=1920, height=1080, fx=fx, fy=fy, cx=cx, cy=cy)\n",
    "        )\n",
    "        pcd.transform([[-1, 0, 0, 0], [0, -1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1]])\n",
    "        if pcd.is_empty():\n",
    "            print(f\"No points were found in the point cloud for {rgb_file}\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        pointcloud_path = os.path.join(point_dir, rgb_file.replace('.png', '.pcd'))\n",
    "        try:\n",
    "            o3d.io.write_point_cloud(pointcloud_path, pcd)\n",
    "            processed_files.append(rgb_file.replace('.png', '.pcd'))\n",
    "            # print(f\"Successfully saved point cloud: {pointcloud_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to save point cloud: {pointcloud_path}. Error: {str(e)}\")\n",
    "    return processed_files\n",
    "\n",
    "missing_files=[]\n",
    "# Process each subfolder\n",
    "for subfolder in os.listdir(base_dir):\n",
    "    subfolder_path = os.path.join(base_dir, subfolder)\n",
    "    if os.path.isdir(subfolder_path):\n",
    "        rgb_mask_dir = os.path.join(subfolder_path, \"rgb_mask\")\n",
    "        depth_mask_dir = os.path.join(subfolder_path, \"depth_mask\")\n",
    "        point_dir = os.path.join(subfolder_path, \"pointcloud\")\n",
    "        processed_files = process_images_and_generate_pointclouds(rgb_mask_dir, depth_mask_dir, point_dir, intrinsics)\n",
    "        if len(processed_files) < len(os.listdir(rgb_mask_dir)):\n",
    "            expected_files = [f.replace('.png', '.pcd') for f in os.listdir(rgb_mask_dir) if f.endswith('.png')]\n",
    "            missing_files.extend(list(set(expected_files) - set(processed_files)))\n",
    "            print(f\"Missing files in {subfolder}: {list(set(expected_files) - set(processed_files))}\")\n",
    "\n",
    "print(\"All missing files across subfolders:\", missing_files)\n",
    "        # process_images_and_generate_pointclouds(rgb_mask_dir, depth_mask_dir, point_dir, intrinsics)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pointcloud merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished merging point clouds.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import open3d as o3d\n",
    "\n",
    "# Define the base directories\n",
    "base_dir_all = \"/home/ubb/Documents/Baxter_isaac/ROS2/src/experiment_recorder/data/baxter/david/baxter/838433/pointcloud\"\n",
    "base_dir_top = \"/home/ubb/Documents/Baxter_isaac/ROS2/src/experiment_recorder/data/baxter/david/baxter/838433/pointcloud_top\"\n",
    "# base_dir_side = \"/home/ubb/Documents/Baxter_isaac/ROS2/src/experiment_recorder/data/baxter/david/baxter/838433/pointcloud_side\"\n",
    "base_dir_merge = \"/home/ubb/Documents/Baxter_isaac/ROS2/src/experiment_recorder/data/baxter/david/baxter/838433/pointcloud_merge2\"\n",
    "\n",
    "\n",
    "# Create the merge directory if it does not exist\n",
    "os.makedirs(base_dir_merge, exist_ok=True)\n",
    "\n",
    "def quaternion_to_rotation_matrix(quat):\n",
    "    \"\"\"Convert quaternion [w, x, y, z] to a 4x4 rotation matrix.\"\"\"\n",
    "    w, x, y, z = quat\n",
    "    tx = 2.0 * x\n",
    "    ty = 2.0 * y\n",
    "    tz = 2.0 * z\n",
    "    twx = tx * w\n",
    "    twy = ty * w\n",
    "    twz = tz * w\n",
    "    txx = tx * x\n",
    "    txy = ty * x\n",
    "    txz = tz * x\n",
    "    tyy = ty * y\n",
    "    tyz = tz * y\n",
    "    tzz = tz * z\n",
    " \n",
    "    return np.array([[1.0 - (tyy + tzz), txy - twz, txz + twy, 0],\n",
    "                     [txy + twz, 1.0 - (txx + tzz), tyz - twx, 0],\n",
    "                     [txz - twy, tyz + twx, 1.0 - (txx + tyy), 0],\n",
    "                     [0, 0, 0, 1]])\n",
    " \n",
    "def transform_point_cloud(pcd, translation, quaternion):\n",
    "    \"\"\"Apply transformation defined by a translation and quaternion rotation to a point cloud.\"\"\"\n",
    "    # Create the transformation matrix\n",
    "    rotation_matrix = quaternion_to_rotation_matrix(quaternion)\n",
    "    rotation_matrix_inversed = np.linalg.inv(rotation_matrix)\n",
    "    #print(rotation_matrix)\n",
    "    transformation_matrix = np.eye(4)\n",
    "    transformation_matrix[:3, :3] = rotation_matrix[:3, :3]\n",
    "    transformation_matrix[:3, 3] = translation\n",
    "\n",
    "    # transformation_matrix = [[1, 0, 0, 0], [0, -1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1]] @ transformation_matrix\n",
    " \n",
    "    # Transform the point cloud\n",
    "    transformed_pcd = pcd.transform(transformation_matrix) # left multiplication\n",
    "    #print(np.asarray(transformed_pcd.points))\n",
    "\n",
    "    return transformed_pcd\n",
    "\n",
    "def load_point_cloud(file_path):\n",
    "    \"\"\"Utility function to load a point cloud.\"\"\"\n",
    "    return o3d.io.read_point_cloud(file_path)\n",
    "\n",
    "def merge_point_clouds(front_pcd, top_pcd):\n",
    "    \"\"\"Merge two point clouds and return the result.\"\"\"\n",
    "    return front_pcd + top_pcd\n",
    "\n",
    "# Iterate over subdirectories in the 'all' directory\n",
    "for subfolder in os.listdir(base_dir_all):\n",
    "    subfolder_all = os.path.join(base_dir_all, subfolder)\n",
    "    subfolder_top = os.path.join(base_dir_top, subfolder)\n",
    "    subfolder_merge = os.path.join(base_dir_merge, subfolder)\n",
    "\n",
    "    # Create subdirectory in merge directory\n",
    "    os.makedirs(subfolder_merge, exist_ok=True)\n",
    "\n",
    "    if os.path.isdir(subfolder_all) and os.path.isdir(subfolder_top):\n",
    "        pointcloud_dir_all = os.path.join(subfolder_all, 'pointcloud')\n",
    "        pointcloud_dir_top = os.path.join(subfolder_top, 'pointcloud')\n",
    "\n",
    "        if os.path.exists(pointcloud_dir_all) and os.path.exists(pointcloud_dir_top):\n",
    "            pointcloud_files_all = {f: os.path.join(pointcloud_dir_all, f) for f in os.listdir(pointcloud_dir_all) if f.endswith('.pcd')}\n",
    "            pointcloud_files_top = {f: os.path.join(pointcloud_dir_top, f) for f in os.listdir(pointcloud_dir_top) if f.endswith('.pcd')}\n",
    "\n",
    "        # Find matching point clouds and merge them\n",
    "            for file_name, path_all in pointcloud_files_all.items():\n",
    "                path_top = pointcloud_files_top.get(file_name)\n",
    "                if path_top:\n",
    "                    # Load point clouds\n",
    "                    front_pcd = load_point_cloud(path_all)\n",
    "                    top_pcd = load_point_cloud(path_top)\n",
    "                    translation_zed = [0.139, -0.68, -1.525] # front modified leo final\n",
    "                    # quaternion_zed =  [0.689, 0.128, 0.086, -0.708] # front modified leo\n",
    "                    quaternion_zed =  [0.690, 0.126, 0.084, -0.708]  # front modified leo final\n",
    "                    translation_zedtop = [-0.508, -0.313, -0.84] # top modified leo final\n",
    "                    # quaternion_zedtop = [0.659, 0.608, 0.332, 0.293] # top modified leo\n",
    "                    quaternion_zedtop = [0.652, 0.615, 0.329, 0.297] # top modified leo final\n",
    "                    transformed_pcd_zed = transform_point_cloud(front_pcd, translation_zed, quaternion_zed)\n",
    "                    transformed_pcd_zedtop = transform_point_cloud(top_pcd, translation_zedtop, quaternion_zedtop)\n",
    "                    transformed_pcd_zedside = transform_point_cloud(top_pcd, translation_zedside, quaternion_zedside)\n",
    "                    # Merge point clouds\n",
    "                    merged_pcd_2 = merge_point_clouds(transformed_pcd_zed, transformed_pcd_zedtop)\n",
    "                    merged_pcd_3 = merge_point_clouds(transformed_pcd_zed, transformed_pcd_zedtop,transformed_pcd_zedside)\n",
    "                    # Save merged point cloud\n",
    "                    output_path = os.path.join(subfolder_merge, file_name)\n",
    "                    o3d.io.write_point_cloud(output_path, merged_pcd_2)\n",
    "                    # print(f\"Merged and saved point cloud to {output_path}\")\n",
    "\n",
    "print(\"Finished merging point clouds.\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pointcloud downsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import open3d as o3d\n",
    "\n",
    "def downsample_pointcloud(pcd_path, output_dir, voxel_size=0.0045):\n",
    "    # Ensure the output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Load the point cloud\n",
    "    pcd = o3d.io.read_point_cloud(pcd_path)\n",
    "    # print(f\"Original point count: {len(pcd.points)}\")\n",
    "\n",
    "    # Downsample the point cloud using voxel downsampling\n",
    "    down_pcd = pcd.voxel_down_sample(voxel_size=voxel_size)\n",
    "    # print(f\"Downsampled point count: {len(down_pcd.points)}\")\n",
    "\n",
    "    # Save the downsampled point cloud\n",
    "    downsampled_filename = os.path.basename(pcd_path).replace('.pcd', f'_downsampled_{voxel_size}.pcd')\n",
    "    downsampled_path = os.path.join(output_dir, downsampled_filename)\n",
    "    o3d.io.write_point_cloud(downsampled_path, down_pcd)\n",
    "    # print(f\"Downsampled point cloud saved to: {downsampled_path}\")\n",
    "\n",
    "def process_subfolders(base_dir, output_base_dir, voxel_size=0.0045):\n",
    "    # Iterate through each subfolder in the base directory\n",
    "    for subdir in os.listdir(base_dir):\n",
    "        subdir_path = os.path.join(base_dir, subdir)\n",
    "        if os.path.isdir(subdir_path):\n",
    "            output_dir = os.path.join(output_base_dir, subdir)\n",
    "            os.makedirs(output_dir, exist_ok=True)  # Ensure the output directory exists\n",
    "\n",
    "            # Process each .pcd file in the subdirectory\n",
    "            for file in os.listdir(subdir_path):\n",
    "                if file.endswith('.pcd'):\n",
    "                    pcd_path = os.path.join(subdir_path, file)\n",
    "                    downsample_pointcloud(pcd_path, output_dir, voxel_size)\n",
    "\n",
    "# Define base directories\n",
    "base_dir = \"/media/ubb/4T/human_demonstration/grasp_point_merge\"\n",
    "output_base_dir = \"/media/ubb/4T/human_demonstration/grasp_point_merge_downsample\"\n",
    "\n",
    "# Process all subfolders\n",
    "process_subfolders(base_dir, output_base_dir)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cvs merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined CSV saved to: /media/ubb/Seagate Backup Plus Drive/human_demonstration/combined_gripper_changes.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the base directory containing the subfolders\n",
    "base_dir = \"/media/ubb/Seagate Backup Plus Drive/human_demonstration/useful_data\"\n",
    "\n",
    "# Initialize an empty list to hold DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Iterate through each subdirectory in the base directory\n",
    "for subdir in os.listdir(base_dir):\n",
    "    subdir_path = os.path.join(base_dir, subdir)\n",
    "    \n",
    "    # Check if it's a directory\n",
    "    if os.path.isdir(subdir_path):\n",
    "        # Specify the path to the CSV file\n",
    "        csv_path = os.path.join(subdir_path, \"gripper_changes_filtered.csv\")\n",
    "        \n",
    "        # Check if the CSV file exists\n",
    "        if os.path.exists(csv_path):\n",
    "            # Read the CSV file and append it to the list\n",
    "            df = pd.read_csv(csv_path)\n",
    "            dataframes.append(df)\n",
    "\n",
    "# Concatenate all dataframes into a single DataFrame\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Define the path for the output CSV file\n",
    "output_csv_path = \"/media/ubb/Seagate Backup Plus Drive/human_demonstration/combined_gripper_changes.csv\"\n",
    "\n",
    "# Save the combined DataFrame to a CSV file\n",
    "combined_df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(f\"Combined CSV saved to: {output_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined CSV saved to: /media/ubb/4T/human_demonstration/combined_all_gripper_changes.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the base directory containing the subfolders\n",
    "csv_path1 = \"/media/ubb/4T/human_demonstration/combined_gripper_changes.csv\"\n",
    "csv_path2 = \"/media/ubb/backup1/human_demonstration/combined_gripper_changes.csv\"\n",
    "csv_path3 = \"/media/ubb/Seagate Backup Plus Drive/human_demonstration/combined_gripper_changes.csv\"\n",
    "\n",
    "\n",
    "# Initialize an empty list to hold DataFrames\n",
    "dataframes = []\n",
    "\n",
    "df1 = pd.read_csv(csv_path1)\n",
    "df2 = pd.read_csv(csv_path2)\n",
    "df3 = pd.read_csv(csv_path3)\n",
    "\n",
    "dataframes.append(df1)\n",
    "dataframes.append(df2)\n",
    "dataframes.append(df3)\n",
    "\n",
    "# Concatenate all dataframes into a single DataFrame\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Define the path for the output CSV file\n",
    "output_csv_path = \"/media/ubb/4T/human_demonstration/combined_all_gripper_changes.csv\"\n",
    "\n",
    "# Save the combined DataFrame to a CSV file\n",
    "combined_df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(f\"Combined CSV saved to: {output_csv_path}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "csv and pointcloud check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered CSV saved to: /media/ubb/4T/human_demonstration/combined_all_gripper_changes_leo.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the combined CSV file\n",
    "csv_path = \"/media/ubb/4T/human_demonstration/combined_all_gripper_changes.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Filter rows where 'subname' contains 'lsshirt_bluedot' or 'lsshirt_darkblue'\n",
    "filtered_df = df[df['subname'].str.contains('lsshirt_bluedot|lsshirt_darkblue', regex=True)]\n",
    "\n",
    "# Define the path for the output CSV file\n",
    "output_csv_path = \"/media/ubb/4T/human_demonstration/combined_all_gripper_changes_leo.csv\"\n",
    "\n",
    "# Save the filtered DataFrame to a new CSV file\n",
    "filtered_df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(f\"Filtered CSV saved to: {output_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing in CSV, but present in pointclouds: set()\n",
      "Missing in pointclouds, but present in CSV: set()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load the CSV file\n",
    "csv_path = \"/media/ubb/My Passport/useful_data/combined_all_gripper_changes.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Extract pc_time values from the DataFrame and convert them to string for matching\n",
    "pc_times = set(df['pc_time'].astype(str))\n",
    "\n",
    "# Path to the directory containing pointcloud subfolders\n",
    "base_dir = \"/media/ubb/My Passport/grasp_point_robot/grasp_point_merge_downsample\"\n",
    "\n",
    "# Set to store the 'xxx' extracted from filenames\n",
    "pcd_times = set()\n",
    "\n",
    "# Iterate through each subfolder and each file within those subfolders\n",
    "for subdir in os.listdir(base_dir):\n",
    "    subdir_path = os.path.join(base_dir, subdir)\n",
    "    if os.path.isdir(subdir_path):\n",
    "        for filename in os.listdir(subdir_path):\n",
    "            if filename.endswith('_downsampled_0.0045.pcd'):\n",
    "                # Extract the 'xxx' part from 'masked_xxx_downsampled_0.0045.pcd'\n",
    "                pcd_time = filename.split('_')[1]\n",
    "                pcd_times.add(pcd_time)\n",
    "\n",
    "# Find differences\n",
    "missing_in_csv = pcd_times - pc_times\n",
    "missing_in_pcd = pc_times - pcd_times\n",
    "\n",
    "print(\"Missing in CSV, but present in pointclouds:\", missing_in_csv)\n",
    "print(\"Missing in pointclouds, but present in CSV:\", missing_in_pcd)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "delete extra pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_in_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/ssshirt_blue/masked_1717506513903735808_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/ssshirt_blue/masked_1717506509471247555_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/ssshirt_blue/masked_1717506504639132401_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/ssshirt_blue/masked_1717506497546558354_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/pant_bluejean/masked_1717509591252639506_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/pant_bluejean/masked_1717509587758704333_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/pant_bluejean/masked_1717509584275542004_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/pant_bluejean/masked_1717509579239879383_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/pant_blackjean/masked_1717509672045838302_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/pant_blackjean/masked_1717509668421326875_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/pant_blackjean/masked_1717509665467985083_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/pant_blackjean/masked_1717509660776103768_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/pant_pink/masked_1717509509811117045_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/pant_pink/masked_1717509506390950877_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/pant_pink/masked_1717509503098299019_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/pant_pink/masked_1717509497666009054_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/lsshirt_bluedot/masked_1717508258914240257_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/lsshirt_bluedot/masked_1717508251737021649_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/lsshirt_bluedot/masked_1717508246298969270_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/lsshirt_bluedot/masked_1717508241525313683_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/lsshirt_bluedot/masked_1717508237506660171_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/lsshirt_bluedot/masked_1717508230713953101_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/lsshirt_darkblue/masked_1717508080265810021_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/lsshirt_darkblue/masked_1717508076519968358_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/lsshirt_darkblue/masked_1717508072415028259_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/lsshirt_darkblue/masked_1717508067521804864_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/lsshirt_darkblue/masked_1717508063425542945_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/lsshirt_darkblue/masked_1717508057127367434_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/lsshirt_grey/masked_1717508344864521042_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/lsshirt_grey/masked_1717508339966727084_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/lsshirt_grey/masked_1717508336077507001_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/lsshirt_grey/masked_1717508327827019325_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/lsshirt_grey/masked_1717508324004246856_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/lsshirt_grey/masked_1717508317094246936_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/lsshirt_lightblue/masked_1717508168972701828_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/lsshirt_lightblue/masked_1717508165616204593_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/lsshirt_lightblue/masked_1717508160720377472_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/lsshirt_lightblue/masked_1717508156427637387_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/lsshirt_lightblue/masked_1717508152664884323_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/lsshirt_lightblue/masked_1717508143397901157_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/lsshirt_lightblue/masked_1717508140296061510_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/lsshirt_white/masked_1717507798449593166_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/lsshirt_white/masked_1717507794683669215_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/lsshirt_white/masked_1717507789851075226_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/lsshirt_white/masked_1717507784754300443_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/lsshirt_white/masked_1717507771599213128_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/lstshirt_black/masked_1717507415612505865_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/lstshirt_black/masked_1717507412260696410_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/lstshirt_black/masked_1717507408773679509_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/lstshirt_black/masked_1717507404880095366_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/lstshirt_black/masked_1717507401452942339_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/lstshirt_black/masked_1717507395682268770_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/lstshirt_brown/masked_1717507503979898371_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/lstshirt_brown/masked_1717507500223904413_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/lstshirt_brown/masked_1717507496801219844_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/lstshirt_brown/masked_1717507493250924557_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/lstshirt_brown/masked_1717507489688639219_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/lstshirt_brown/masked_1717507483717604114_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/lstshirt_purple/masked_1717507233057099870_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/lstshirt_purple/masked_1717507229306180102_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/lstshirt_purple/masked_1717507226418377792_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/lstshirt_purple/masked_1717507221728807342_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/lstshirt_purple/masked_1717507218165649741_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/lstshirt_purple/masked_1717507210463677022_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/lstshirt_purple/masked_1717507205288278148_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/lstshirt_white/masked_1717507610431726171_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/lstshirt_white/masked_1717507606881107176_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/lstshirt_white/masked_1717507603460627312_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/lstshirt_white/masked_1717507599901292737_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/lstshirt_white/masked_1717507596691257273_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/lstshirt_white/masked_1717507588913829789_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/lstshirt_white/masked_1717507584541992292_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/lstshirt_whitehor/masked_1717507334032253503_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/lstshirt_whitehor/masked_1717507330347671470_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/lstshirt_whitehor/masked_1717507326388139836_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/lstshirt_whitehor/masked_1717507320477936283_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/lstshirt_whitehor/masked_1717507316451161317_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/lstshirt_whitehor/masked_1717507309344675969_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/napkin_brown30/masked_1717508489504187503_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/napkin_brown30/masked_1717508485481075297_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/napkin_brown30/masked_1717508480447964758_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/napkin_brown45/masked_1717509076304237589_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/napkin_brown45/masked_1717509073292697360_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/napkin_brown45/masked_1717509067249751975_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/napkin_fleek30/masked_1717508800504472616_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/napkin_fleek30/masked_1717508796881542122_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/napkin_fleek30/masked_1717508792056500886_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/napkin_fleek45/masked_1717508933393433157_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/napkin_fleek45/masked_1717508929566234197_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/napkin_fleek45/masked_1717508923866248114_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/napkin_grey30/masked_1717508677496293942_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/napkin_grey30/masked_1717508673547330254_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/napkin_grey30/masked_1717508667697448925_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/napkin_grey30/masked_1717508661056301660_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/napkin_grey45/masked_1717508994807894106_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/napkin_grey45/masked_1717508990783825242_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/napkin_grey45/masked_1717508987293265765_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/napkin_grey45/masked_1717508980587364970_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/napkin_pink30/masked_1717508560219653770_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/napkin_pink30/masked_1717508556530577347_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/napkin_pink30/masked_1717508550898439805_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/napkin_pink45/masked_1717509134574657508_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/napkin_pink45/masked_1717509131286437718_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/napkin_pink45/masked_1717509125922827782_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/napkin_red30/masked_1717508742123946936_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/napkin_red30/masked_1717508738301388710_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/napkin_red30/masked_1717508732260926508_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/napkin_red45/masked_1717508871479920645_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/napkin_red45/masked_1717508867922833080_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/napkin_red45/masked_1717508861690049119_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/ssshirt_bluebl/masked_1717506854984941531_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/ssshirt_bluebl/masked_1717506850827904513_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/ssshirt_bluebl/masked_1717506845731645398_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/ssshirt_bluebl/masked_1717506838347046146_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/ssshirt_pink/masked_1717506596201403681_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/ssshirt_pink/masked_1717506592584324429_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/ssshirt_pink/masked_1717506588422736368_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/ssshirt_pink/masked_1717506581848622300_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/ssshirt_white/masked_1717506768238431657_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/ssshirt_white/masked_1717506764477891938_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/ssshirt_white/masked_1717506760185016915_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/ssshirt_white/masked_1717506752256896307_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/ssshirt_yellow/masked_1717506694754782472_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/ssshirt_yellow/masked_1717506690326265353_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/ssshirt_yellow/masked_1717506685897604898_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/ssshirt_yellow/masked_1717506677714844353_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/sstshirt_green/masked_1717506154598775012_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/sstshirt_green/masked_1717506150707613267_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/sstshirt_green/masked_1717506145408453156_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/sstshirt_green/masked_1717506137218431855_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/sstshirt_grey/masked_1717506074078057365_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/sstshirt_grey/masked_1717506069311386105_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/sstshirt_grey/masked_1717506063949331231_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/sstshirt_grey/masked_1717506060724161118_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/sstshirt_grey/masked_1717506053678901923_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/sstshirt_whitenf/masked_1717506408772016572_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/sstshirt_whitenf/masked_1717506405349440280_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/sstshirt_whitenf/masked_1717506400859403689_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/sstshirt_whitenf/masked_1717506393681470556_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/sstshirt_whitenf/masked_1717506390660170681_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/sstshirt_whitenf/masked_1717506387366341633_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/towel_blue/masked_1717505740088796606_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/towel_blue/masked_1717505737337749031_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/towel_blue/masked_1717505734381407261_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/towel_blue/masked_1717505727267111763_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/towel_pink/masked_1717505817224025617_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/towel_pink/masked_1717505814610502851_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/towel_pink/masked_1717505810519158481_downsampled_0.0045.pcd\n",
      "Deleted: /media/ubb/4T/human_demonstration/grasp_point_merge_downsample/towel_pink/masked_1717505803812798126_downsampled_0.0045.pcd\n",
      "Finished deleting pointcloud files.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Base directory where the pointclouds are stored\n",
    "base_dir = \"/media/ubb/My Passport/grasp_point_robot/grasp_point_merge_downsample\"\n",
    "\n",
    "# Iterate over all subfolders and delete the specified pointcloud files\n",
    "for subdir in os.listdir(base_dir):\n",
    "    subdir_path = os.path.join(base_dir, subdir)\n",
    "    if os.path.isdir(subdir_path):\n",
    "        #pointcloud_dir = os.path.join(subdir_path, 'pointcloud')  # Adjust if pointclouds are directly under subdir\n",
    "        for filename in os.listdir(subdir_path):\n",
    "            if filename.endswith('.pcd'):\n",
    "                # Extract the 'xxx' part from 'masked_xxx_downsampled_0.0045.pcd'\n",
    "                pcd_time = filename.split('_')[1]\n",
    "                if pcd_time in missing_in_csv:\n",
    "                    file_path = os.path.join(subdir_path, filename)\n",
    "                    os.remove(file_path)\n",
    "                    print(f\"Deleted: {file_path}\")\n",
    "\n",
    "print(\"Finished deleting pointcloud files.\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "delete extra row in csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows after deletion: 6329\n",
      "Rows with pc_times in {'1719142079084016418', '1719140552895662872', '1719156442063866156', '1718819865018888256', '1719059271281482711'} have been deleted.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to the CSV file\n",
    "csv_path = \"/media/ubb/4T/human_demonstration/combined_all_gripper_changes.csv\"\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# # Display the number of rows before deletion for confirmation\n",
    "# print(\"Number of rows before deletion:\", len(df))\n",
    "\n",
    "# # Delete the row where 'pc_time' is 1718819865018888256\n",
    "# df = df[df['pc_time'] != 1718819865018888256]\n",
    "delete_pc_times = {'1719142079084016418', '1719140552895662872', '1719156442063866156', '1718819865018888256', '1719059271281482711'}\n",
    "\n",
    "# Delete the rows where 'pc_time' is in the set of delete_pc_times\n",
    "df = df[~df['pc_time'].isin(delete_pc_times)]\n",
    "\n",
    "\n",
    "# Display the number of rows after deletion to confirm the row is deleted\n",
    "print(\"Number of rows after deletion:\", len(df))\n",
    "\n",
    "# Save the updated DataFrame back to CSV\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "print(f\"Rows with pc_times in {delete_pc_times} have been deleted.\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "another way, crop the pointcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quaternion_to_rotation_matrix(quat):\n",
    "    \"\"\"Convert quaternion [w, x, y, z] to a 4x4 rotation matrix.\"\"\"\n",
    "    w, x, y, z = quat\n",
    "    tx = 2.0 * x\n",
    "    ty = 2.0 * y\n",
    "    tz = 2.0 * z\n",
    "    twx = tx * w\n",
    "    twy = ty * w\n",
    "    twz = tz * w\n",
    "    txx = tx * x\n",
    "    txy = ty * x\n",
    "    txz = tz * x\n",
    "    tyy = ty * y\n",
    "    tyz = tz * y\n",
    "    tzz = tz * z\n",
    " \n",
    "    return np.array([[1.0 - (tyy + tzz), txy - twz, txz + twy, 0],\n",
    "                     [txy + twz, 1.0 - (txx + tzz), tyz - twx, 0],\n",
    "                     [txz - twy, tyz + twx, 1.0 - (txx + tyy), 0],\n",
    "                     [0, 0, 0, 1]])\n",
    " \n",
    "def transform_point_cloud(pcd, translation, quaternion):\n",
    "    \"\"\"Apply transformation defined by a translation and quaternion rotation to a point cloud.\"\"\"\n",
    "    # Create the transformation matrix\n",
    "    rotation_matrix = quaternion_to_rotation_matrix(quaternion)\n",
    "    rotation_matrix_inversed = np.linalg.inv(rotation_matrix)\n",
    "    #print(rotation_matrix)\n",
    "    transformation_matrix = np.eye(4)\n",
    "    transformation_matrix[:3, :3] = rotation_matrix[:3, :3]\n",
    "    transformation_matrix[:3, 3] = translation\n",
    "\n",
    "    # transformation_matrix = [[1, 0, 0, 0], [0, -1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1]] @ transformation_matrix\n",
    " \n",
    "    # Transform the point cloud\n",
    "    transformed_pcd = pcd.transform(transformation_matrix) # left multiplication\n",
    "    #print(np.asarray(transformed_pcd.points))\n",
    "\n",
    "    return transformed_pcd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "\n",
    "def apply_aabb_cropping(pcd, min_bound, max_bound):\n",
    "    # Create an axis-aligned bounding box\n",
    "    aabb = o3d.geometry.AxisAlignedBoundingBox(min_bound=min_bound, max_bound=max_bound)\n",
    "    # Crop the point cloud\n",
    "    cropped_pcd = pcd.crop(aabb)\n",
    "    return cropped_pcd\n",
    "\n",
    "# Example usage\n",
    "pcd_path = \"/home/ubb/Documents/Baxter_isaac/ROS2/src/experiment_recorder/data/baxter/lipeng/napkin_pink30_5/pointcloud/1719056738504144079.pcd\"\n",
    "pcd = o3d.io.read_point_cloud(pcd_path)\n",
    "\n",
    "# Coordinates from CloudCompare (example, replace these with actual values from your screenshot)\n",
    "x_min = -0.493813\n",
    "x_max = 0.527173\n",
    "y_min = -0.534935\n",
    "y_max = 0.488354\n",
    "z_min = 0.523\n",
    "z_max = 1.45\n",
    "\n",
    "min_bound = np.array([x_min, y_min, z_min])\n",
    "max_bound = np.array([x_max, y_max, z_max])\n",
    "\n",
    "# Crop the point cloud\n",
    "cropped_pcd = apply_aabb_cropping(pcd, min_bound, max_bound)\n",
    "\n",
    "# Optionally visualize the cropped point cloud\n",
    "o3d.visualization.draw_geometries([cropped_pcd])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "more specific see pointcloud_merge_threecamera.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pointcloud registration global registration and local registration(icp) but do not work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Downsample with a voxel size 0.015.\n",
      ":: Estimate normal with search radius 0.030.\n",
      ":: Compute FPFH feature with search radius 0.075.\n",
      ":: Downsample with a voxel size 0.015.\n",
      ":: Estimate normal with search radius 0.030.\n",
      ":: Compute FPFH feature with search radius 0.075.\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.transform import Rotation as R\n",
    "import os\n",
    "import ast\n",
    "import csv\n",
    "import numpy as np\n",
    "import cv2\n",
    "import open3d as o3d\n",
    "import os\n",
    "import copy\n",
    "\n",
    "def find_nearest_timestamp(target_timestamp, timestamps):\n",
    "    timestamps = np.array(timestamps, dtype=np.int64)\n",
    "    idx = np.abs(timestamps - target_timestamp).argmin()\n",
    "    return timestamps[idx]\n",
    "\n",
    "def load_point_cloud(file_path):\n",
    "    return o3d.io.read_point_cloud(file_path)\n",
    "\n",
    "def quaternion_to_rotation_matrix(quat):\n",
    "    \"\"\"Convert quaternion [w, x, y, z] to a 4x4 rotation matrix.\"\"\"\n",
    "    w, x, y, z = quat\n",
    "    tx = 2.0 * x\n",
    "    ty = 2.0 * y\n",
    "    tz = 2.0 * z\n",
    "    twx = tx * w\n",
    "    twy = ty * w\n",
    "    twz = tz * w\n",
    "    txx = tx * x\n",
    "    txy = ty * x\n",
    "    txz = tz * x\n",
    "    tyy = ty * y\n",
    "    tyz = tz * y\n",
    "    tzz = tz * z\n",
    " \n",
    "    return np.array([[1.0 - (tyy + tzz), txy - twz, txz + twy, 0],\n",
    "                     [txy + twz, 1.0 - (txx + tzz), tyz - twx, 0],\n",
    "                     [txz - twy, tyz + twx, 1.0 - (txx + tyy), 0],\n",
    "                     [0, 0, 0, 1]])\n",
    " \n",
    "def transform_point_cloud(pcd, translation, quaternion):\n",
    "    \"\"\"Apply transformation defined by a translation and quaternion rotation to a point cloud.\"\"\"\n",
    "    # Create the transformation matrix\n",
    "    rotation_matrix = quaternion_to_rotation_matrix(quaternion)\n",
    "    rotation_matrix_inversed = np.linalg.inv(rotation_matrix)\n",
    "    #print(rotation_matrix)\n",
    "    transformation_matrix = np.eye(4)\n",
    "    transformation_matrix[:3, :3] = rotation_matrix[:3, :3]\n",
    "    transformation_matrix[:3, 3] = translation\n",
    "\n",
    "    # transformation_matrix = [[1, 0, 0, 0], [0, -1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1]] @ transformation_matrix\n",
    " \n",
    "    # Transform the point cloud\n",
    "    transformed_pcd = pcd.transform(transformation_matrix) # left multiplication\n",
    "    #print(np.asarray(transformed_pcd.points))\n",
    "\n",
    "    return transformed_pcd\n",
    "\n",
    "def preprocess_point_cloud(pcd, voxel_size):\n",
    "    print(\":: Downsample with a voxel size %.3f.\" % voxel_size)\n",
    "    pcd_down = pcd.voxel_down_sample(voxel_size)\n",
    "\n",
    "    radius_normal = voxel_size * 2\n",
    "    print(\":: Estimate normal with search radius %.3f.\" % radius_normal)\n",
    "    pcd_down.estimate_normals(\n",
    "        o3d.geometry.KDTreeSearchParamHybrid(radius=radius_normal, max_nn=30))\n",
    "\n",
    "    radius_feature = voxel_size * 5\n",
    "    print(\":: Compute FPFH feature with search radius %.3f.\" % radius_feature)\n",
    "    pcd_fpfh = o3d.pipelines.registration.compute_fpfh_feature(\n",
    "        pcd_down,\n",
    "        o3d.geometry.KDTreeSearchParamHybrid(radius=radius_feature, max_nn=100))\n",
    "    return pcd_down, pcd_fpfh\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def draw_registration_result(source, target, transformation):\n",
    "    source_temp = copy.deepcopy(source)\n",
    "    target_temp = copy.deepcopy(target)\n",
    "    source_temp.paint_uniform_color([1, 0.706, 0])\n",
    "    target_temp.paint_uniform_color([0, 0.651, 0.929])\n",
    "    source_temp.transform(transformation)\n",
    "    o3d.visualization.draw_geometries([source_temp, target_temp])\n",
    "\n",
    "def execute_icp(source, target, threshold=0.02, init_pose=None, icp_type=None):\n",
    "    # Set initial alignment\n",
    "    if init_pose is None:\n",
    "        init_pose = np.identity(4)  # Identity matrix, no initial alignment\n",
    "    \n",
    "    # Compute point to point ICP\n",
    "    if icp_type == 'point_to_point':\n",
    "        reg_p2p = o3d.pipelines.registration.registration_icp(\n",
    "            source, target, threshold, init_pose,\n",
    "            o3d.pipelines.registration.TransformationEstimationPointToPoint(),\n",
    "            o3d.pipelines.registration.ICPConvergenceCriteria(max_iteration=2000))\n",
    "        print(reg_p2p)\n",
    "        transformation = reg_p2p.transformation\n",
    "    elif icp_type == 'point_to_plane':\n",
    "        # Ensure normals are estimated\n",
    "        source.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.1, max_nn=30))\n",
    "        target.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.1, max_nn=30))\n",
    "        reg_p2plane = o3d.pipelines.registration.registration_icp(\n",
    "            source, target, threshold, init_pose,\n",
    "            o3d.pipelines.registration.TransformationEstimationPointToPlane())\n",
    "        print(reg_p2plane)\n",
    "        transformation = reg_p2plane.transformation\n",
    "    \n",
    "    return transformation\n",
    "\n",
    "def execute_global_registration(source_down, target_down, source_fpfh,\n",
    "                                target_fpfh, voxel_size):\n",
    "    distance_threshold = voxel_size * 1.5\n",
    "    print(\":: RANSAC registration on downsampled point clouds.\")\n",
    "    print(\"   Since the downsampling voxel size is %.3f,\" % voxel_size)\n",
    "    print(\"   we use a liberal distance threshold %.3f.\" % distance_threshold)\n",
    "    result = o3d.pipelines.registration.registration_ransac_based_on_feature_matching(\n",
    "        source_down, target_down, source_fpfh, target_fpfh, True,\n",
    "        distance_threshold,\n",
    "        o3d.pipelines.registration.TransformationEstimationPointToPoint(False),\n",
    "        3, [\n",
    "            o3d.pipelines.registration.CorrespondenceCheckerBasedOnEdgeLength(\n",
    "                0.9),\n",
    "            o3d.pipelines.registration.CorrespondenceCheckerBasedOnDistance(\n",
    "                distance_threshold)\n",
    "        ], o3d.pipelines.registration.RANSACConvergenceCriteria(100000, 0.999))\n",
    "    return result\n",
    "\n",
    "def refine_registration(source, target, source_fpfh, target_fpfh, voxel_size):\n",
    "    distance_threshold = voxel_size * 0.4\n",
    "    result = o3d.pipelines.registration.registration_icp(\n",
    "        source, target, distance_threshold, result_ransac.transformation,\n",
    "        o3d.pipelines.registration.TransformationEstimationPointToPoint())\n",
    "    return result\n",
    "\n",
    "def apply_aabb_cropping(pcd, min_bound, max_bound):\n",
    "    # Create an axis-aligned bounding box\n",
    "    aabb = o3d.geometry.AxisAlignedBoundingBox(min_bound=min_bound, max_bound=max_bound)\n",
    "    # Crop the point cloud\n",
    "    cropped_pcd = pcd.crop(aabb)\n",
    "    return cropped_pcd\n",
    "\n",
    "x_min = -0.493813\n",
    "x_max = 0.527173\n",
    "y_min = -0.534935\n",
    "y_max = 0.488354\n",
    "z_min = 0.523\n",
    "z_max = 1.45\n",
    "\n",
    "min_bound = np.array([x_min, y_min, z_min])\n",
    "max_bound = np.array([x_max, y_max, z_max])\n",
    "\n",
    "index = 130\n",
    "pointcloud_folder = \"/home/ubb/Documents/Baxter_isaac/ROS2/src/experiment_recorder/data/baxter/lipeng/napkin_pink30_5/pointcloud\"\n",
    "pointcloud_top_folder = \"/home/ubb/Documents/Baxter_isaac/ROS2/src/experiment_recorder/data/baxter/lipeng/napkin_pink30_5/pointcloud_top\"\n",
    "pointcloud_side_folder = \"/home/ubb/Documents/Baxter_isaac/ROS2/src/experiment_recorder/data/baxter/lipeng/napkin_pink30_5/pointcloud_side\"\n",
    "    \n",
    "pointcloud_files = sorted(os.listdir(pointcloud_folder))\n",
    "pointcloud_top_files = sorted(os.listdir(pointcloud_top_folder))\n",
    "pointcloud_side_files = sorted(os.listdir(pointcloud_side_folder))\n",
    "    \n",
    "pointcloud_top_timestamps = [int(f.split('.')[0]) for f in pointcloud_top_files]\n",
    "pointcloud_side_timestamps = [int(f.split('.')[0]) for f in pointcloud_side_files]\n",
    "\n",
    "# for pointcloud_file in posintcloud_files:\n",
    "pointcloud_file = pointcloud_files[index]\n",
    "target_timestamp = int(pointcloud_file.split('.')[0])\n",
    "        \n",
    "nearest_top_timestamp = find_nearest_timestamp(target_timestamp, pointcloud_top_timestamps)\n",
    "nearest_side_timestamp = find_nearest_timestamp(target_timestamp, pointcloud_side_timestamps)\n",
    "        \n",
    "pointcloud_path = os.path.join(pointcloud_folder, pointcloud_file)\n",
    "top_pointcloud_path = os.path.join(pointcloud_top_folder, f\"{nearest_top_timestamp}.pcd\")\n",
    "side_pointcloud_path = os.path.join(pointcloud_side_folder, f\"{nearest_side_timestamp}.pcd\")\n",
    "\n",
    "# Load point clouds\n",
    "front_pcd = load_point_cloud(pointcloud_path)\n",
    "top_pcd = load_point_cloud(top_pointcloud_path)\n",
    "side_pcd = load_point_cloud(side_pointcloud_path)\n",
    "\n",
    "translation_zed = [0.139, -0.68, -1.525] # front modified leo final\n",
    "# quaternion_zed =  [0.689, 0.128, 0.086, -0.708] # front modified leo\n",
    "quaternion_zed =  [0.690, 0.126, 0.084, -0.708]  # front modified leo final\n",
    "\n",
    "translation_zedtop = [-0.508, -0.313, -0.84] # top modified leo final\n",
    "# quaternion_zedtop = [0.659, 0.608, 0.332, 0.293] # top modified leo\n",
    "quaternion_zedtop = [0.652, 0.615, 0.329, 0.297] # top modified leo final\n",
    "\n",
    "\n",
    "translation_zedside = [1.0, -1.030, -0.01] # side modified leo final\n",
    "# quaternion_zedside =  [0.392,  -0.691, -0.578,  0.195] # side modified leo\n",
    "# quaternion_zedside =  [  0.389, -0.683, -0.587,  0.193] \n",
    "quaternion_zedside =  [0.385, -0.687, -0.588,  0.186]  # side modified leo final\n",
    "\n",
    "cropped_pcd_zed = apply_aabb_cropping(front_pcd, min_bound, max_bound)\n",
    "cropped_pcd_top = apply_aabb_cropping(top_pcd, min_bound, max_bound)\n",
    "cropped_pcd_side = apply_aabb_cropping(side_pcd, min_bound, max_bound)\n",
    "\n",
    "transformed_pcd_zed = transform_point_cloud(cropped_pcd_zed, translation_zed, quaternion_zed)\n",
    "transformed_pcd_zedtop = transform_point_cloud(cropped_pcd_top, translation_zedtop, quaternion_zedtop)\n",
    "transformed_pcd_zedside = transform_point_cloud(cropped_pcd_side, translation_zedside, quaternion_zedside)\n",
    "# transformed_pcd_zed = transform_point_cloud(front_pcd, translation_zed, quaternion_zed)\n",
    "# transformed_pcd_zedtop = transform_point_cloud(top_pcd, translation_zedtop, quaternion_zedtop)\n",
    "# transformed_pcd_zedside = transform_point_cloud(side_pcd, translation_zedside, quaternion_zedside)\n",
    "initial_transform = np.eye(4)\n",
    "\n",
    "voxel_size = 0.015\n",
    "source_down, source_fpfh = preprocess_point_cloud(transformed_pcd_zed, voxel_size)\n",
    "target_down, target_fpfh = preprocess_point_cloud(transformed_pcd_zedtop, voxel_size)\n",
    "\n",
    "# result_ransac = execute_global_registration(source_down, target_down,source_fpfh, target_fpfh,voxel_size)\n",
    "# print(result_ransac)\n",
    "# initial_transform=result_ransac.transformation\n",
    "\n",
    "\n",
    "# print(\"Initial alignment\")\n",
    "# evaluation = o3d.pipelines.registration.evaluate_registration(\n",
    "#     transformed_pcd_zedtop, transformed_pcd_zed, 0.02, initial_transform)\n",
    "# print(evaluation)\n",
    "\n",
    "#  # Assuming some initial transformation or use the identity matrix\n",
    "# aligned_transformation = execute_icp(transformed_pcd_zedtop, transformed_pcd_zed, init_pose=initial_transform, icp_type='point_to_point')\n",
    "# transformed_pcd_zedtop.transform(aligned_transformation)\n",
    "\n",
    "\n",
    "# draw_registration_result(transformed_pcd_zed, transformed_pcd_zedtop, initial_transform)\n",
    "# draw_registration_result(front_pcd, top_pcd, trans_init)\n",
    "\n",
    "\n",
    "vis = o3d.visualization.Visualizer()\n",
    "vis.create_window(width=1920, height=1080)\n",
    "\n",
    "origin = o3d.geometry.TriangleMesh.create_coordinate_frame(size=0.5, origin=[0, 0, 0])\n",
    "\n",
    "# vis.add_geometry(transformed_pcd_zedside)\n",
    "vis.add_geometry(transformed_pcd_zed)\n",
    "vis.add_geometry(transformed_pcd_zedtop)\n",
    "vis.run()\n",
    "vis.destroy_window()\n",
    "\n",
    "# merged_point_cloud = transformed_pcd_zed + transformed_pcd_zedtop + transformed_pcd_zedside\n",
    "# output_path = os.path.join(base_dir, \"merged_complete_pointcloud.pcd\")\n",
    "# o3d.io.write_point_cloud(output_path, merged_point_cloud)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "avoid e-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "future work. 3d gussian spliting to generate the [merged pointcloud]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "others no necessary code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing all subfolders.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# Path to the directory containing all subfolders\n",
    "base_dir = \"/media/ubb/4T/human_demonstration/grasp_point_all\"\n",
    "\n",
    "# Iterate over all subdirectories in the base directory\n",
    "for subdir in os.listdir(base_dir):\n",
    "    subdir_path = os.path.join(base_dir, subdir)\n",
    "    \n",
    "    # Check if it's a directory\n",
    "    if os.path.isdir(subdir_path):\n",
    "        # Create an 'rgb' subdirectory\n",
    "        depth_dir = os.path.join(subdir_path, \"depth\")\n",
    "        os.makedirs(depth_dir, exist_ok=True)\n",
    "        \n",
    "        # # Move all .png images to the 'rgb' directory and convert them to .jpg\n",
    "        for filename in os.listdir(subdir_path):\n",
    "            if filename.endswith('.png'):\n",
    "                old_file_path = os.path.join(subdir_path, filename)\n",
    "                new_filename = filename[:-4] + '.jpg'\n",
    "                new_file_path = os.path.join(depth_dir, new_filename)\n",
    "                \n",
    "                # Rename and move the file to the 'depth' directory\n",
    "                os.rename(old_file_path, new_file_path)\n",
    "                # # Open the PNG image and convert it to JPEG\n",
    "                # with Image.open(old_file_path) as img:\n",
    "                #     # Create a new filename with .jpg extension\n",
    "                #     new_filename = filename[:-4] + '.jpg'\n",
    "                #     new_file_path = os.path.join(rgb_dir, new_filename)\n",
    "                    \n",
    "                #     # Convert and save the image\n",
    "                #     img.save(new_file_path, 'JPEG')\n",
    "                \n",
    "                # # Optionally, delete the old .png file\n",
    "                # os.remove(old_file_path)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Finished processing all subfolders.\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "extra unneccessary code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timezone, timedelta\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('/home/ubb/Documents/Baxter_isaac/ROS2/src/experiment_recorder/data/baxter/david/baxter/838433/processed_output_zed.csv')\n",
    "\n",
    "# Function to convert ROS timestamp to readable datetime in UTC\n",
    "def convert_timestamp_to_uk_time(timestamps_ns):\n",
    "    # Convert nanosecond timestamp to seconds, adjust for timezone (UTC+0)\n",
    "    return [datetime.fromtimestamp(ts / 1e9, timezone.utc) for ts in timestamps_ns]\n",
    "\n",
    "# Convert all timestamps in the 'time' column to UK time\n",
    "df['real_time'] = convert_timestamp_to_uk_time(df['time'])\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "df.to_csv('/home/ubb/Documents/Baxter_isaac/ROS2/src/experiment_recorder/data/baxter/david/baxter/838433/processed_output_zed_with_real_time.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "\n",
    "def load_point_cloud(file_path):\n",
    "    \"\"\"Utility function to load a point cloud from a file.\"\"\"\n",
    "    return o3d.io.read_point_cloud(file_path)\n",
    "\n",
    "# Load the point cloud from a file\n",
    "pc = load_point_cloud('/home/ubb/Documents/Baxter_isaac/ROS2/src/experiment_recorder/data/baxter/david/baxter/838433/pointcloud_merge_threecamera/masked_1724954266649801567.pcd')\n",
    "\n",
    "# Initialize the visualizer\n",
    "vis = o3d.visualization.Visualizer()\n",
    "vis.create_window('Point Cloud Visualization', width=1920, height=1080)\n",
    "\n",
    "# Optionally add a coordinate frame for reference\n",
    "origin = o3d.geometry.TriangleMesh.create_coordinate_frame(size=0.5, origin=[0, 0, 0])\n",
    "# vis.add_geometry(origin)\n",
    "\n",
    "# Add the loaded point cloud to the visualizer\n",
    "vis.add_geometry(pc)\n",
    "\n",
    "# Run the visualizer until the window is closed\n",
    "vis.run()\n",
    "\n",
    "# Destroy the window after closing\n",
    "vis.destroy_window()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
